{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6888697d-ce38-403b-b0af-102e14f64429",
   "metadata": {},
   "source": [
    "# Fusion Chip Conversion Utility Example\n",
    "\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/IBM/aihwkit/blob/master/notebooks/analog_fusion.ipynb\" target=\"_parent\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/>\n",
    "</a>\n",
    "\n",
    "## 1) Goal of the notebook\n",
    "This is an example of how to convert the trained weights of the Anlaog hardware-aware trained LeNet5 model to conductance values in MicroSiemens and save the output to the specified file. The converted conductances can be programmed on the Analog Fusion chip using the [Analog Cloud Composer application](https://aihw-composer.draco.res.ibm.com).\n",
    "\n",
    "Check out this [example notebook](https://github.com/IBM/aihwkit/blob/master/notebooks/tutorial/hw_aware_training.ipynb) for more details about Analog hardware-aware training using the [AIHWKIT](https://github.com/IBM/aihwkit).\n",
    "\n",
    "## 2) Overview of the Fusion chip\n",
    "The Fusion chip is a first-generation AI Analog chip by IBM Research. The chip has 512 word-lines (WL) and 2048 bit-lines. Each WL/BL address as a Phase Changed Memory (PCM) device in series with an access transistor that can be individually accessed. Therefore, there are 512x2048 or 1,048,576 PCM devices in total. This implies that the chip can hold neural networks with about 1 million weights. \n",
    "To learn more about the technology behind the IBM Fusion chip, check out this [blog](https://research.ibm.com/blog/the-hardware-behind-analog-ai). \n",
    "\n",
    "<div>\n",
    "<center><img src=\"img/fusion-chip.png\" width=\"500\"/></center>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e1941-0bf9-4ff0-80fd-7fde24c9a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the aihwkit and other needed libraries. \n",
    "# You can uncomment this section or parts of it if the libraries are installed in your environment. \n",
    "import os\n",
    "return_code = os.system(\"which nvidia-smi\")\n",
    "#if torch.cuda.is_available():\n",
    "if return_code == 0:\n",
    "    DEVICE = 'cuda'\n",
    "    !wget https://aihwkit-gpu-demo.s3.us-east.cloud-object-storage.appdomain.cloud/aihwkit-0.9.1+cuda117-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl -P data\n",
    "    !pip install data/aihwkit-0.9.1+cuda117-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "    USE_CUDA = 1\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    !pip install aihwkit\n",
    "    USE_CUDA = 0\n",
    "\n",
    "!pip install matplotlib\n",
    "!pip install mpl-scatter-density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28305c3c-2844-47e7-8f2f-4e72c46f6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prerequisites\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ff4cb0-8437-4df2-a8c2-d66bb15d5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from aihwkit.\n",
    "from aihwkit.nn import AnalogConv2dMapped, AnalogLinearMapped, AnalogSequential\n",
    "from aihwkit.simulator.presets.web import  WebComposerInferenceRPUConfig\n",
    "from aihwkit.utils.legacy import convert_legacy_checkpoint\n",
    "from aihwkit.utils.export import  fusion_export,  fusion_import\n",
    "from aihwkit.inference.converter.fusion import FusionConductanceConverter\n",
    "from aihwkit.simulator.configs import InferenceRPUConfig\n",
    "from aihwkit.nn.modules.base import AnalogLayerBase\n",
    "from aihwkit.simulator.configs.utils import WeightNoiseType, WeightClipType, WeightModifierType\n",
    "from aihwkit.simulator.configs.utils import MappingParameter\n",
    "from aihwkit.simulator.presets.utils import PresetIOParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f4592b-392f-4507-bc23-8d5be1fdeaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code to print out the rpu_config that was used in the model.\n",
    "def print_rpu_fields( model: nn.Module) -> None:\n",
    "    \"\"\"Print the Inference RPU Config fields\"\"\"\n",
    "\n",
    "    print(\"\\n>>> STARTING _print_rpu_fields() \")\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if not isinstance(module, AnalogLayerBase):\n",
    "            continue\n",
    "\n",
    "        print(f\"RPUConfig of module {name}:\")\n",
    "        tile = next(module.analog_tiles())\n",
    "        print(tile.rpu_config)\n",
    "        print(tile.tile)\n",
    "        print(\"-------------\")\n",
    "    print(\"\\n>>> ENDING _print_rpu_fields() \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d40aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Analog model.  In this example, create a LeNet5 model.  Note: replace it with your own model\n",
    "N_CLASSES = 10\n",
    "def create_analog_lenet5_network():\n",
    "    \"\"\"Returns a LeNet5 inspired analog model.\"\"\"\n",
    "\n",
    "    rpu_config = WebComposerInferenceRPUConfig()\n",
    "    # print('rpu_config: ', rpu_config)\n",
    "    channel = [16, 32, 512, 128]\n",
    "    model = AnalogSequential(\n",
    "        AnalogConv2dMapped(in_channels=1, out_channels=channel[0], kernel_size=5, stride=1,\n",
    "                     rpu_config=rpu_config),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        AnalogConv2dMapped(in_channels=channel[0], out_channels=channel[1], kernel_size=5, stride=1,\n",
    "                     rpu_config=rpu_config),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Tanh(),\n",
    "        nn.Flatten(),\n",
    "        AnalogLinearMapped(in_features=channel[2], out_features=channel[3], rpu_config=rpu_config),\n",
    "        nn.Tanh(),\n",
    "        AnalogLinearMapped(in_features=channel[3], out_features=N_CLASSES, rpu_config=rpu_config),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb617d05-542b-4879-adaf-0e3e98d561dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c88b597-ccfe-48ed-a3ef-8b45d2572a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "N_CLASSES = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "PATH_DATASET = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf1c4762-9fba-497e-8e50-89e5cf228475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    \"\"\"Load images for train from torchvision datasets.\"\"\"\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_set = datasets.FashionMNIST(PATH_DATASET, download=True, train=True, transform=transform)\n",
    "    val_set = datasets.FashionMNIST(PATH_DATASET, download=True, train=False, transform=transform)\n",
    "    train_data = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validation_data = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_data, validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f318663a-97d9-4606-8094-1e71d415561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(validation_data, model, criterion):\n",
    "    \"\"\"Validate the trained network\n",
    "    Args:\n",
    "        validation_data (DataLoader): Validation set to perform the evaluation\n",
    "        model (nn.Module): Trained model to be evaluated\n",
    "        criterion (nn.CrossEntropyLoss): criterion to compute loss\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    predicted_ok = 0\n",
    "    total_images = 0\n",
    "\n",
    "    model.eval()\n",
    "    for images, labels in validation_data:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        pred = model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        total_images += labels.size(0)\n",
    "        predicted_ok += (predicted == labels).sum().item()\n",
    "        accuracy = predicted_ok/total_images*100\n",
    "        error = (1-predicted_ok/total_images)*100\n",
    "\n",
    "    epoch_loss = total_loss / len(validation_data.dataset)\n",
    "\n",
    "    return epoch_loss, error, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2fb969-c6f5-441d-804b-752393029c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the example checkpoint file for LeNet5 model by uncomment the line below if you have not done that.\n",
    "!wget https://github.com/IBM-AI-Hardware-Center/Composer/raw/main/hwa-trained-lenet5-mapped.pth -P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c12339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model by loading the checkpoint. Note: replace with your data as applicable.\n",
    "WEIGHT_PATH = 'data/hwa-trained-lenet5-mapped.pth'\n",
    "\n",
    "model = create_analog_lenet5_network()\n",
    "\n",
    "# Load the state dictionaries from the checkpoint file\n",
    "state_dict = torch.load(WEIGHT_PATH, DEVICE)\n",
    "\n",
    "# Convert the legacy checkpoint if the checkpoint was captured with the aihwkit version 0.7.1.  Otherwise you do not need to do the next step\n",
    "state_dict, _ = convert_legacy_checkpoint(state_dict, model)\n",
    "\n",
    "# load the state dictionaries to the model.\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f66446-5322-4d20-abbc-5ff4f9081bc0",
   "metadata": {},
   "source": [
    "## Evaluate the model before applying the conductances read from the fusion chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3706e3-a3a4-4e72-818b-7017f830256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, validation_data = load_images()\n",
    "\n",
    "if USE_CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "_, error, accuracy = run_inference(validation_data, model, criterion)\n",
    "\n",
    "print(f'Error after inference: {error:.2f}%\\t'\n",
    "      f'Accuracy after inference: {accuracy:.2f}%\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b30dc1-d199-4ddf-af47-d89ca8e82bec",
   "metadata": {},
   "source": [
    "## Convert the weights in the model to conductance.  The conductance unit is MicroSiemens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4158f0d5-e5c3-4c7e-8840-ad7c220194d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Gmax value.  The value must be between 10 and 40 inclusively\n",
    "Gmax = 40\n",
    "# Get the conductance converter for the fusion chip\n",
    "g_converter=FusionConductanceConverter(Gmax)\n",
    "# Convert the weights to conductance and write the data to the specified file name. NOTE: please change the name of the file as needed.\n",
    "Target_csv = 'data/analog_lenet5.csv'\n",
    "_, params, state_dict = fusion_export(model, file_name=Target_csv, g_converter=g_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eee95b7-24ed-4d61-ab28-5afb0c8cf6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the file by uncommenting out the line below.  NOTE: change the file name to your specified file name in the above step.\n",
    "#!ls -l data/analog_lenet5.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ac7dadc-a83a-4b42-9433-6f1c938e8f16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1) Programming the conductances on Fusion Chip using Analog Composer \n",
    "\n",
    "After converting the neural network model weights to their equivalent conductance values, you can program these values on the Analog Fusion chip by submitting a custom fusion inference job using the [Composer application](https://aihw-composer.draco.res.ibm.com/). Follow the steps outlined in the figure below:\n",
    "\n",
    "<center><img src=\"img/fusion-ui.png\" width=\"1000\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492819d-8548-44c9-b0b1-df5d3fd9efc5",
   "metadata": {},
   "source": [
    "## 2.2) Downloading the model data from the Fusion chip\n",
    "\n",
    "After the inference job is completed, the programmed conductance values can be downloaded from the composer application in the form of CSV file. You can apply the programmed values to the model using fusion_import routine.\n",
    "\n",
    "Below is an example of how to apply the programmed values obtained from the Fusion chip to your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad388f98-3f8f-48d0-85ea-0f56b436593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a sample analog_fusion_lenet5.csv obtained from a Fusion inference job. \n",
    "!wget https://github.com/IBM-AI-Hardware-Center/Composer/raw/main/data/analog_fusion_lenet5.csv -P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca96af20-45de-4155-a647-f09395f9c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the filename to the file that contains the programmed values.\n",
    "Programmed_csv = 'data/analog_fusion_lenet5.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9205321-b127-4119-b12a-bc29e30bdb36",
   "metadata": {},
   "source": [
    "## 2.3) Using the fusion_import utility to set the model weights\n",
    "This function imports the data from the Fusion chip and sets the model weights. Drift compensation is applied to the weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "394e3796-39f9-4f24-af0f-08d1b511fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the programmed values to the model. \n",
    "programmed_model = fusion_import(Programmed_csv, model, params=params, state_dict=state_dict, g_converter=g_converter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a04d0-c3f5-45aa-8434-a0e2bcf3e3cd",
   "metadata": {},
   "source": [
    "## Evaluate the model after applying the conductances read from the fusion chip.\n",
    "You will notice the small difference between the accuracy for the initial model and the programmed model (model weights were read after one programming round on the Fusion chip). This shows that the algorithmic drift compensation technique that is used in AIHWKIT is helping recover the errors due to the noise that was introduced by the Analog Fusion chip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b9b4e-2b4c-46b8-bf29-014340e24dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if USE_CUDA:\n",
    "       programmed_model.cuda()\n",
    "    \n",
    "_, error, accuracy = run_inference(validation_data, programmed_model, criterion)\n",
    "\n",
    "print(f'Error after inference: {error:.2f}%\\t'\n",
    "      f'Accuracy after inference: {accuracy:.2f}%\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd6e9f-79e0-4e08-a3e3-305465346417",
   "metadata": {},
   "source": [
    "## 2.5) Additional Analysis of the Conductance values \n",
    "### Plotting the Target and Programmed Conductance values\n",
    "In what follows, Programmed refers to the conductance values read after programming the PCM chip. Target refers to the original conductance values. Conductances experience drift in PCM due to the Analog hardware non-idealities. Therefore, the read-programmed values are expected to drift from the target conductance values. \n",
    "\n",
    "In what follows, we will plot target vs. programmed conductance values and also plot the errors that were "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12e9ebc1-c9db-4d04-8d8c-96925fb8e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fa6d07f-b766-45d2-a5b4-32e2fc5b25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routine to convert the csv file to npy file for matplotlib plotting.\n",
    "def convert_to_npy(csv_file: str, npy_file: str):\n",
    "    one_list = []\n",
    "    with open(csv_file) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i < 6:\n",
    "                continue\n",
    "            elif i >= 6:\n",
    "                actual_line = list((line.rstrip('\\n')).split(','))\n",
    "                one_list += actual_line\n",
    "    f.close()\n",
    "    one_array = array(one_list, dtype='float64')\n",
    "    np.save(npy_file, one_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c6ac027-7998-4453-9133-de82d3324896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Target and Programmed csv files to npy.\n",
    "Target_npy = 'data/analog_lenet5.npy'\n",
    "Programmed_npy = 'data/analog_fusion_lenet5.npy'\n",
    "convert_to_npy(Target_csv, Target_npy)\n",
    "convert_to_npy(Programmed_csv, Programmed_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d1afeb4-6046-4205-9d61-82012e3fd2a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Target_array = np.load(Target_npy)\n",
    "Programmed_array = np.load(Programmed_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74397d5-bed3-4760-9cfe-89d8f6c26246",
   "metadata": {},
   "source": [
    "## Graph the Target and Programmed conductance values using a scatter plot with density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3113d2-f46f-4ca0-a8f2-df61a9b70259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpl_scatter_density # adds projection='scatter_density'\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Code reused from https://stackoverflow.com/questions/20105364/how-can-i-make-a-scatter-plot-colored-by-density\n",
    "# \"Viridis-like\" colormap with white background\n",
    "white_viridis = LinearSegmentedColormap.from_list('white_viridis', [\n",
    "    (0, '#ffffff'),\n",
    "    (1e-20, '#440053'),\n",
    "    (0.2, '#404388'),\n",
    "    (0.4, '#2a788e'),\n",
    "    (0.6, '#21a784'),\n",
    "    (0.8, '#78d151'),\n",
    "    (1, '#fde624'),\n",
    "], N=256)\n",
    "\n",
    "def using_mpl_scatter_density(fig, x, y):\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='scatter_density')\n",
    "    density = ax.scatter_density(x, y, cmap=white_viridis)\n",
    "    fig.colorbar(density, label='Number of points per pixel')\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "using_mpl_scatter_density(fig, Target_array, Programmed_array)\n",
    "plt.xlabel('Target Conductance')\n",
    "plt.ylabel('Programmed Conductance')\n",
    "plt.title(\"Target Conductance versus Programmed Conductance Scatter plot with density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8a953-f2d8-4881-970d-de99bfda2d75",
   "metadata": {},
   "source": [
    "## Plot the histogram for the Target and Programmed conductance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effefeb-38b2-4eb3-8629-0872e0d4fc64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist([Target_array, Programmed_array], color=[\n",
    "         'Blue', 'Green'], label=['Target', 'Programmed'])\n",
    "plt.xlabel('Conductance Range')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(['Target', 'Programmed'], loc='upper right')\n",
    "plt.title(\"Conductance Histogram 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1aeff8-a675-4d7f-9de4-13f8950cf4ef",
   "metadata": {},
   "source": [
    "## Calculate the error between the Programmed and Target conductance and their standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3b5b21e-c118-46d0-9db5-de6deccb6d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "TC_sum = sum(abs(Target_array))\n",
    "PC_sum = sum(abs(Programmed_array))\n",
    "# Calculate weight error by normalizing programmed conductance by (TC_sum / PC_sum) to account for conductance drift.\n",
    "C_error = (100 * (Programmed_array * (TC_sum / PC_sum) - Target_array)) / Gmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88d78208-f9d5-4cbe-b7aa-476121f995c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Std_err = np.std(C_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a1c3c-ba00-4a69-b11d-016e7fa5406b",
   "metadata": {},
   "source": [
    "##  Plot the conductance errors between Target and Programmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97368d04-6bab-4a84-9186-2851e1b6d3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graph conductance error using Scatter plot with density\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "# fig = plt.figure()\n",
    "x_axis = range(C_error.size)\n",
    "using_mpl_scatter_density(fig, x_axis, C_error)\n",
    "plt.ylabel('Conductance Error')\n",
    "plt.xlabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dfcb74-ccd9-4b06-8dca-3b4f51a26548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram of the Target vs. Programmed conductance errors\n",
    "plt.figure(figsize=(16, 10))\n",
    "# Code reused from https://stackoverflow.com/a/49389122\n",
    "# Use matplotlib hist() instead of Seaborn histplot()  \n",
    "# hist() returns info required to find points for line plot:\n",
    "# 'n' - bin frequency (bar height)\n",
    "# 'bins' - bin boundaries\n",
    "n, bins, patches = plt.hist(\n",
    "    x=C_error, \n",
    "    bins=50, \n",
    "    density=True,\n",
    "    color=\"purple\",\n",
    "    alpha=0.3 # faded histogram \n",
    ")\n",
    "# find bin midpoints\n",
    "bin_centers = 0.5*(bins[1:]+bins[:-1])\n",
    "# draw lines connecting successive points\n",
    "plt.plot(bin_centers, n, linewidth=4, color=\"purple\") \n",
    "\n",
    "plt.xlabel(\"Conductance Error\", labelpad=20)\n",
    "plt.ylabel(\"Frequency\", labelpad=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
